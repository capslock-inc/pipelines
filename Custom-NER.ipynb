{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "entity_data = pd.read_csv(\"asset/product-list.csv\")\n",
    "list(entity_data['product'])\n",
    "\n",
    "entity_data_json = json.dumps({\n",
    "    \"product\":list(entity_data['product'])\n",
    "    },indent=4)\n",
    "with open(\"asset/entity.json\",\"w\") as file:\n",
    "    file.write(entity_data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open (\"asset/entity.json\") as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "if 'ner' not in nlp.pipe_names:\n",
    "    ner = nlp.create_pipe('ner')\n",
    "    nlp.add_pipe(ner)\n",
    "else:\n",
    "    ner = nlp.create_pipe('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tracemalloc import start\n",
    "import pandas as pd\n",
    "\n",
    "ner_data = pd.read_csv(\"asset/Product-NER.csv\")\n",
    "data , char_start, char_end = list (ner_data.question),list(ner_data.start),list(ner_data.end)\n",
    "for idx, elem in enumerate(data):\n",
    "    print(\"-\"+elem[char_start[idx]:char_end[idx]]+\"-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNER Training data Format:\n",
    "```\n",
    "[('training sentence',{'entities': [(start-char, end-char, 'entity-code')]})]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNER_training_data = []\n",
    "for sentence, start_char, end_char in zip(data, char_start, char_end):\n",
    "    temp = (\n",
    "        sentence,{\n",
    "            \"entities\":[\n",
    "                (start_char,end_char,\"PRODUCT\")\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    "    CNER_training_data.append(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNER_training_data_json = json.dumps({\n",
    "    \"data\":CNER_training_data\n",
    "},indent=4)\n",
    "with open(\"asset/product_ner_training_data.json\",\"w\") as file:\n",
    "    file.write(CNER_training_data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_CNER_training_data(json_data):\n",
    "    entities = []\n",
    "    for elem in json_data:\n",
    "        temp =[]\n",
    "        for loc in elem[1]['entities']:\n",
    "            temp.append(tuple(loc))\n",
    "        entities.append({\n",
    "            \"entities\":temp\n",
    "        })\n",
    "    refined_data = []\n",
    "    for idx,elem in enumerate(json_data):\n",
    "        refined_data.append(\n",
    "            tuple([elem[0],entities[idx]])\n",
    "        )\n",
    "    return refined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"asset/product_ner_training_data.json\",\"r\") as file:\n",
    "    file = json.load(file)\n",
    "CNER_training_data=  json_to_CNER_training_data(file['data'])\n",
    "CNER_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train_spacy(train_data, iterations):\n",
    "    nlp = spacy.blank('en')\n",
    "    if 'ner' not in nlp.pipe_names:\n",
    "        # ner = nlp.create_pipe('ner')\n",
    "        nlp.add_pipe(\"ner\", last=True)\n",
    "       \n",
    "    # Add labels\n",
    "    for _, annotations in train_data:\n",
    "         for ent in annotations.get('entities'):\n",
    "            ner.add_label(ent[2])\n",
    "\n",
    "    # Disable all pipes other than 'ner' during training\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "        optimizer = nlp.begin_training()\n",
    "        \n",
    "        train_loss = []\n",
    "        \n",
    "        # Go through the training data N times\n",
    "        for itn in range(iterations):\n",
    "            print(\"Starting iteration \" + str(itn))\n",
    "\n",
    "            random.shuffle(train_data)\n",
    "\n",
    "            losses = {}\n",
    "            misalligned_count = 0\n",
    "\n",
    "            for batch in spacy.util.minibatch(train_data, size=2):\n",
    "                for text, annotations in batch:    \n",
    "                    try:\n",
    "                        doc = nlp.make_doc(text)\n",
    "                        example = spacy.training.Example.from_dict(doc, annotations)\n",
    "                        nlp.update(\n",
    "                            [example],\n",
    "                            drop=0.2,\n",
    "                            sgd=optimizer,\n",
    "                            losses=losses)\n",
    "\n",
    "                    except ValueError as e:\n",
    "                        misalligned_count += 1\n",
    "                        print(f'Ignoring misaligned entity...\\n{(text,annotations)}')\n",
    "                        pass\n",
    "\n",
    "                train_loss.append(losses.get('ner'))\n",
    "                print(f'losses (iteration {itn}): {losses}')\n",
    "            \n",
    "        # Visualizing the loss\n",
    "        plt.figure(figsize=(10,6))\n",
    "        plt.plot([*range(len(train_loss))], train_loss, color = 'magenta')\n",
    "        plt.title('Loss at every iteration')\n",
    "        plt.xlabel('Iteration Number')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.show()\n",
    "            \n",
    "    return nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_nlp = train_spacy(train_data=CNER_training_data,iterations=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(product_nlp, open('models/product_nlp.pkl', \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=pickle.load(open(\"models/product_nlp.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1362/3018919082.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "from spacy import displacy\n",
    "def extract_product(user_input, visualize = False):\n",
    "    product_NLP = product_nlp\n",
    "    doc = product_nlp(user_input)\n",
    "\n",
    "    extracted_entities = []\n",
    "    for ent in doc.ents:\n",
    "        extracted_entities.append((ent.text, ent.start_char, ent.end_char, ent.label_))\n",
    "\n",
    "    if visualize == True:\n",
    "        colors = {\"PRODUCT\": \"linear-gradient(90deg, #aa9cfc, #fc9ce7)\"}\n",
    "        options = {\"ents\": [\"PRODUCT\"], \"colors\": colors}\n",
    "        html = displacy.render(doc, style = 'ent', options = options)\n",
    "        display(HTML(html));\n",
    "    return extracted_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1362/1154706093.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "from spacy import displacy\n",
    "def extract_product2(user_input, visualize = False):\n",
    "    product_NLP = nlp\n",
    "    doc = nlp(user_input)\n",
    "\n",
    "    extracted_entities = []\n",
    "    for ent in doc.ents:\n",
    "        extracted_entities.append((ent.text, ent.start_char, ent.end_char, ent.label_))\n",
    "\n",
    "    if visualize == True:\n",
    "        colors = {\"PRODUCT\": \"linear-gradient(90deg, #aa9cfc, #fc9ce7)\"}\n",
    "        options = {\"ents\": [\"PRODUCT\"], \"colors\": colors}\n",
    "        html = displacy.render(doc, style = 'ent', options = options)\n",
    "        display(HTML(html));\n",
    "    return extracted_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">when is my \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #aa9cfc, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    active\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       " subscription is expiring</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = extract_product2(\"when is my active subscription\",visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'when is my PRODUCT expiring'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"when is my d365 expiring\"\n",
    "newtext = text[:x[0][1]] + x[0][3]+\" \"+ text[x[0][1]-1+len(x[0][3])-1:]\n",
    "newtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e426eb422ee72ecab5ec3ed5d296a61d193577bd5d7289265f51c8d958dc6079"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
